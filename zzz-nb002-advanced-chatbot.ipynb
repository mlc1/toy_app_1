{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# Cómo construir un Chatbot avanzado con memoria de sesión usando LangChain\n",
    "* Aplicación Chatbot LLM Avanzada.\n",
    "    * Podrá tener una conversación.\n",
    "    * Recordará interacciones previas: tendrá memoria.\n",
    "    * Podrá tener diferentes memorias para diferentes sesiones de usuario.\n",
    "    * Podrá recordar un número limitado de mensajes: memoria limitada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0399355-dece-4701-9bf4-4c204fe74929",
   "metadata": {},
   "source": [
    "## Conceptos incluidos\n",
    "* Modelo de Chat vs. Modelo LLM:\n",
    "    * El Modelo de Chat se basa en mensajes.\n",
    "    * El Modelo LLM se basa en texto sin formato.\n",
    "* Historial de Chat: permite que el Modelo de Chat recuerde interacciones previas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48386f20-c929-48a9-8720-0953fcd67dd0",
   "metadata": {},
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ee060-21f2-4e01-b283-1fd656dac1e9",
   "metadata": {},
   "source": [
    "#### Después de descargar el código del repositorio de github en tu computadora\n",
    "En la terminal:\n",
    "* cd nombre_del_proyecto\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### Para abrir el notebook con Jupyter Notebooks\n",
    "En la terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Ve a la carpeta de notebooks y abre el notebook correcto.\n",
    "\n",
    "#### Para ver el código en Virtual Studio Code o tu editor de preferencia.\n",
    "* abre Virtual Studio Code o tu editor de preferencia.\n",
    "* abre la carpeta del proyecto\n",
    "* abre el archivo 002-advanced-chatbot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2adf5-45d7-4c4b-aa6b-3176daa86e0e",
   "metadata": {},
   "source": [
    "## Crea tu archivo .env\n",
    "* En el repositorio de github hemos incluido un archivo llamado .env.example\n",
    "* Renombra ese archivo a .env y aquí es donde agregarás tus claves de API confidenciales. Recuerda incluir:\n",
    "* OPENAI_API_KEY=tu_clave_de_api_de_openai\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=tu_clave_de_api_de_langchain\n",
    "* LANGCHAIN_PROJECT=tu_nombre_de_proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a63ff6-99ff-4629-b965-547d12a99ba6",
   "metadata": {},
   "source": [
    "Llamaremos a nuestro proyecto LangSmith **002-advanced-chatbot**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67075f4a-6c25-41db-b851-51df80ffd927",
   "metadata": {},
   "source": [
    "## Truco para evitar las molestas advertencias de depreciación de LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49577308-4ed9-4c4b-a59a-a825b33ea75d",
   "metadata": {},
   "source": [
    "En este ejercicio usaremos la cadena heredada LLMChain de LangChain. Funciona bien, pero LangChain muestra una molesta advertencia de depreciación. Para evitarlo, ingresaremos el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157958ab-f806-4ced-9a9a-bd22cf61e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "\n",
    "# Filtra las advertencias de depreciación de LangChain para evitar que se muestren\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bf0fd-0661-4350-8979-53266845c8dd",
   "metadata": {},
   "source": [
    "## Conéctate con el archivo .env ubicado en el mismo directorio de este notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b08934-b7f0-4e8a-b5f7-9df3c8bdbc66",
   "metadata": {},
   "source": [
    "Si estás usando el shell de poetry pre-cargado, no necesitas instalar el siguiente paquete porque ya está pre-cargado para ti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4cec3-cc60-49f1-a24e-793b3be7cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Carga las variables de entorno desde el archivo .env\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Instala LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5ddc8-1f67-4efc-b26f-5a7bfb8fda5c",
   "metadata": {},
   "source": [
    "Si estás usando el shell de poetry pre-cargado, no necesitas instalar el siguiente paquete porque ya está pre-cargado para ti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Conéctate con un LLM y comienza una conversación con él"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646540d-6dae-468c-b5e0-5348106d034b",
   "metadata": {},
   "source": [
    "Si estás usando el shell de poetry pre-cargado, no necesitas instalar el siguiente paquete porque ya está pre-cargado para ti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* Para este proyecto, usaremos OpenAI's gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Inicializa el chatbot con el modelo gpt-3.5-turbo de OpenAI\n",
    "chatbot = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf96c51",
   "metadata": {},
   "source": [
    "* Podemos usar un modelo local con ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9100c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chatbot = ChatOllama(model='gpt-oss:20b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1d409-7f2f-40a4-90c5-ad77dad3edce",
   "metadata": {},
   "source": [
    "* Mensaje Humano: la entrada del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc0613-fb6d-4c82-a614-9e7307714303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Define una lista de mensajes para enviar al chatbot\n",
    "messagesToTheChatbot = [\n",
    "    HumanMessage(content=\"Mi color favorito es el azul.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b36ec-341a-47bc-af32-30cfb939810d",
   "metadata": {},
   "source": [
    "#### Llama al ChatModel (el LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db815e32-8e60-46b3-8cce-fbf40e378397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Blue is such a calming and peaceful color. It's often associated with stability and trustworthiness. What do you like most about the color blue?\", response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 13, 'total_tokens': 43}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-484b5288-6948-495f-88a1-cdd01e48f626-0', usage_metadata={'input_tokens': 13, 'output_tokens': 30, 'total_tokens': 43})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoca al chatbot con los mensajes definidos\n",
    "chatbot.invoke(messagesToTheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913fc8c-254f-410d-aa8f-35eb0898855e",
   "metadata": {},
   "source": [
    "#### Rastrea la operación en LangSmith\n",
    "* [Abre LangSmith aquí](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62b67b-9798-4705-8b8a-dbfdf8c93ed8",
   "metadata": {},
   "source": [
    "## Verifica si el Chatbot recuerda tu color favorito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ead4ee-bda3-4c52-9bdb-7bf234733055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I'm not able to know your favorite color as an AI assistant. Can you please tell me what your favorite color is?\", response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 13, 'total_tokens': 42}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-75666902-eef4-4507-ba38-75b0b7e8a886-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoca al chatbot para preguntar cuál es el color favorito\n",
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"¿Cuál es mi color favorito?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec947e-b9b7-43e3-ac67-60027e049f3c",
   "metadata": {},
   "source": [
    "* Como puedes ver, nuestro Chatbot no puede recordar nuestra interacción previa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0143e-8bc8-45ad-ac6f-05aaf659c683",
   "metadata": {},
   "source": [
    "## Agreguemos memoria a nuestro Chatbot\n",
    "* Usaremos el paquete ChatMessageHistory.\n",
    "* Guardaremos la memoria del Chatbot en un diccionario de python llamado chatbotMemory.\n",
    "* Definiremos la función get_session_history para crear un session_id para cada conversación.\n",
    "* Usaremos el runnable incorporado RunnableWithMesageHistory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2680fc-8b7a-429f-a570-3c3dc4681037",
   "metadata": {},
   "source": [
    "Si estás usando el shell de poetry pre-cargado, no necesitas instalar el siguiente paquete porque ya está pre-cargado para ti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23533a37-6060-4d32-9b0c-36a9ea57a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1d395-0656-46f4-a14e-70cd3e30e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Diccionario para almacenar la memoria del chatbot por sesión\n",
    "chatbotMemory = {}\n",
    "\n",
    "# Función para obtener el historial de chat de una sesión\n",
    "# input: session_id, output: chatbotMemory[session_id]\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    # Si no existe una entrada para este session_id, crea una nueva\n",
    "    if session_id not in chatbotMemory:\n",
    "        chatbotMemory[session_id] = ChatMessageHistory()\n",
    "    return chatbotMemory[session_id]\n",
    "\n",
    "# Crea un chatbot con historial de mensajes\n",
    "chatbot_with_message_history = RunnableWithMessageHistory(\n",
    "    chatbot, \n",
    "    get_session_history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ef148-1c37-4006-bb02-780d994803bd",
   "metadata": {},
   "source": [
    "#### ¿Qué es BaseChatMessageHistory y qué hace?\n",
    "BaseChatMessageHistory es lo que se llama una **clase base abstracta** en Python. [Ve más información sobre esto aquí](https://api.python.langchain.com/en/latest/chat_history/langchain_core.chat_history.BaseChatMessageHistory.html). Esto significa que sirve como una plantilla o un **plano** fundacional para otras clases. Describe un conjunto de métodos y estructuras que cualquier clase que herede de ella debe implementar o cumplir, pero no se puede usar para crear objetos directamente.\n",
    "\n",
    "Aquí hay un desglose más simple de lo que significa que `BaseChatMessageHistory` sea una clase base abstracta:\n",
    "\n",
    "1. **Plano para otras clases:** Proporciona una estructura predefinida que otras clases pueden seguir. Piensa en ello como un esquema o una lista de verificación para construir algo; especifica lo que debe incluirse, pero no es el producto final.\n",
    "\n",
    "2. **No se pueden crear instancias:** No puedes crear una instancia de una clase base abstracta. Intentar crear un objeto directamente desde `BaseChatMessageHistory` resultaría en un error porque está destinado a ser una guía, no algo para usar directamente.\n",
    "\n",
    "3. **Requiere implementación:** Cualquier clase que herede de esta clase base abstracta necesita implementar métodos específicos descritos en `BaseChatMessageHistory`, como métodos para agregar mensajes, recuperar mensajes y borrar mensajes. La clase establece las reglas, y las subclases deben seguir estas reglas proporcionando los detalles operativos reales.\n",
    "\n",
    "4. **Propósito en el diseño:** Usar una clase base abstracta ayuda a garantizar la coherencia y la corrección en la implementación de clases que la extienden. Es una forma de hacer cumplir ciertas funcionalidades en cualquier subclase, asegurándose de que todas se comporten como se espera sin reescribir el mismo código varias veces.\n",
    "\n",
    "En general, el concepto de una clase base abstracta se trata de establecer estándares y reglas, dejando los detalles específicos de la ejecución a ser definidos por las subclases que heredan de ella."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c9c5e",
   "metadata": {},
   "source": [
    "#### Expliquemos el código anterior en términos simples\n",
    "El código anterior gestiona la memoria del chatbot de las conversaciones basándose en identificadores de sesión. Aquí hay un desglose de lo que hacen los diferentes componentes:\n",
    "\n",
    "1. **chatbotMemory**:\n",
    "    - `chatbotMemory = {}`: Esto inicializa un diccionario vacío donde se almacenarán los IDs de sesión y sus respectivos historiales de chat.\n",
    "\n",
    "2. **Función get_session_history**:\n",
    "    - Esta función, `get_session_history`, toma un `session_id` como argumento y devuelve el historial de chat asociado con esa sesión.\n",
    "    - Si un historial de chat para el `session_id` dado no existe en `chatbotMemory`, se crea una nueva instancia de `ChatMessageHistory` y se asigna a ese `session_id` en el diccionario.\n",
    "    - La función asegura que cada sesión tenga su propio historial de chat único, almacenado y recuperado usando el ID de sesión.\n",
    "\n",
    "3. **chatbot_with_message_history**:\n",
    "    - `chatbot_with_message_history = RunnableWithMessageHistory(chatbot, get_session_history)`: Esta línea crea una instancia de `RunnableWithMessageHistory` usando dos argumentos: `chatbot` y `get_session_history`.\n",
    "    - El `chatbot` se pasa junto con la función `get_session_history`. Esta configuración integra el chatbot con la funcionalidad para manejar historiales de chat específicos de la sesión, permitiendo que el chatbot mantenga la continuidad y el contexto en las conversaciones a través de diferentes sesiones.\n",
    "    - **Aprende más sobre RunnableWithMessageHistory** [aquí](https://python.langchain.com/v0.1/docs/expression_language/how_to/message_history/).\n",
    "\n",
    "En general, el código organiza y gestiona la memoria de un chatbot, permitiéndole manejar diferentes sesiones con los usuarios de manera efectiva al recordar mensajes previos dentro de cada sesión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98864e16-66bb-49fb-a72f-2ceb5523b361",
   "metadata": {},
   "source": [
    "#### RunnableWithMessageHistory\n",
    "**Al invocar un nuevo RunnableWithMessageHistory, especificamos el historial de chat correspondiente usando un parámetro configurable**. Digamos que queremos crear una memoria de chat para una sesión de usuario, llamémosla sesión1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51d451-ed97-4752-88df-de8072e45f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la configuración para la sesión 1\n",
    "session1 = {\"configurable\": {\"session_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3961a-b565-45b5-a45f-2332ab03cd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a bold and vibrant choice! Red is often associated with energy, passion, and strength. Do you have a specific reason why red is your favorite color?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Mi color favorito es el rojo.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a4aae-c392-439d-a7ea-4ae91a677075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"¿Cuál es mi color favorito?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d37c98-3883-4210-a162-5302e109e743",
   "metadata": {},
   "source": [
    "## Cambiemos ahora el session_id y veamos qué pasa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b484c1-da0b-4e90-a304-afbbebe63b76",
   "metadata": {},
   "source": [
    "Ahora creemos una memoria de chat para otra sesión de usuario, llamémosla sesión2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82b3e0-7897-4aa8-b554-1985a3af4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la configuración para la sesión 2\n",
    "session2 = {\"configurable\": {\"session_id\": \"002\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75248e78-2662-4faa-bd41-4aa2b7963d19",
   "metadata": {},
   "source": [
    "Si el chatbot está usando esta nueva memoria para la sesión2, no podrá recordar nada de la conversación anterior en la sesión1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d0fc2-4360-4205-8cc7-bc7275295eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have that information. Can you please tell me what your favorite color is?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 2\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"¿Cuál es mi color favorito?\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ec598-2b9f-4da1-b169-b270f820df9e",
   "metadata": {},
   "source": [
    "## Volvamos a la sesión1 y veamos si la memoria todavía está ahí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c102a-1f06-490f-88b7-cb6e6380d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la configuración para la sesión 1\n",
    "session1 = {\"configurable\": {\"session_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f61f9a-b8d5-4149-97cd-c7b6c8683bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"¿Cuál es mi color favorito?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd5156-977b-42e9-89e9-7797f6895ebc",
   "metadata": {},
   "source": [
    "Como podemos ver, el chatbot ahora puede recordar la conversación de la sesión1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037264c-71aa-47f2-9512-e78c12761eaa",
   "metadata": {},
   "source": [
    "## Nuestro ChatBot ahora tiene memoria de sesión. Comprobemos si recuerda la conversación de la sesión2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2a638-7968-4475-8cf8-9af8440f3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la configuración para la sesión 2\n",
    "session2 = {\"configurable\": {\"session_id\": \"002\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367cb8f-1109-45ca-8e7a-1b76a096ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Julio! It's nice to meet you. If you'd like to share your favorite color with me, I'd be happy to remember it for future reference.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 2\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Mi nombre es Julio.\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac2ecd-9800-467e-a612-9e3264185875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Julio.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 2\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"¿Cuál es mi nombre?\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649bdcc-a393-406b-8121-4cd25ae11163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"¿Cuál es mi color favorito?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbce7cd-399d-42f3-be81-bff26506cfbc",
   "metadata": {},
   "source": [
    "## Nuestro chatBot ahora recuerda cada una de nuestras conversaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39070b3d-5de9-4751-966e-98b17a4db745",
   "metadata": {},
   "source": [
    "## La importancia de gestionar el historial de conversación\n",
    "* La memoria de un chatbot se incluye en la ventana de contexto del LLM, por lo que, si no se gestiona, puede desbordarla.\n",
    "* **Ahora vamos a aprender cómo limitar el tamaño de la memoria de un chatbot**.\n",
    "* Primero, echemos un vistazo a lo que hay en la memoria de nuestro chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09547883-82fc-480a-8f58-fd7fbc007fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'001': InMemoryChatMessageHistory(messages=['Human: My favorite color is red.', AIMessage(content=\"That's a bold and vibrant choice! Red is often associated with energy, passion, and strength. Do you have a specific reason why red is your favorite color?\", response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 13, 'total_tokens': 46}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e5fde172-58ef-4f73-b463-a2a463d0a1f7-0', usage_metadata={'input_tokens': 13, 'output_tokens': 33, 'total_tokens': 46}), AIMessage(content='Your favorite color is red!', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 62, 'total_tokens': 68}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-99eebba4-d387-4a22-b717-1180116d043a-0', usage_metadata={'input_tokens': 62, 'output_tokens': 6, 'total_tokens': 68}), AIMessage(content='Your favorite color is red!', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 72, 'total_tokens': 78}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-77733a8c-0946-494a-8dd5-adaef779c8cf-0', usage_metadata={'input_tokens': 72, 'output_tokens': 6, 'total_tokens': 78}), AIMessage(content='Your favorite color is red!', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 82, 'total_tokens': 88}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-23843ab4-9019-420b-827b-9d356c769699-0', usage_metadata={'input_tokens': 82, 'output_tokens': 6, 'total_tokens': 88})]), '002': InMemoryChatMessageHistory(messages=[\"Human: What's my favorite color?\", AIMessage(content=\"I'm sorry, I don't have that information. Can you please tell me what your favorite color is?\", response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 13, 'total_tokens': 35}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cf503e96-07c9-456a-8eff-9f4e74b962e3-0', usage_metadata={'input_tokens': 13, 'output_tokens': 22, 'total_tokens': 35}), AIMessage(content=\"Hello Julio! It's nice to meet you. If you'd like to share your favorite color with me, I'd be happy to remember it for future reference.\", response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 50, 'total_tokens': 83}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0e3f7722-ef1a-424d-a968-4f60683a15e5-0', usage_metadata={'input_tokens': 50, 'output_tokens': 33, 'total_tokens': 83}), AIMessage(content='Your name is Julio.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 87, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4181b321-0aeb-4b69-bfb9-5c0f70ad24b5-0', usage_metadata={'input_tokens': 87, 'output_tokens': 5, 'total_tokens': 92})])}\n"
     ]
    }
   ],
   "source": [
    "# Imprime el contenido de la memoria del chatbot\n",
    "print(chatbotMemory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a7229-ea29-468b-93e1-b2b52951b47c",
   "metadata": {},
   "source": [
    "* Ahora, **definamos una función para limitar el número de mensajes almacenados en la memoria y agreguémosla a nuestra cadena con .assign**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33a1bb-d3c4-4011-99c7-105e3d7051e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Función para limitar el número de mensajes almacenados\n",
    "def limited_memory_of_messages(messages, number_of_messages_to_keep=2):\n",
    "    return messages[-number_of_messages_to_keep:]\n",
    "\n",
    "# Define un prompt para el chatbot\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente útil. Responde todas las preguntas lo mejor que puedas.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Crea una cadena con memoria limitada\n",
    "limitedMemoryChain = (\n",
    "    RunnablePassthrough.assign(messages=lambda x: limited_memory_of_messages(x[\"messages\"]))\n",
    "    | prompt \n",
    "    | chatbot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff26a10-27aa-48ef-a3f0-867d3f819c79",
   "metadata": {},
   "source": [
    "* La función limited_memory_of_messages te permite recortar la lista de mensajes almacenados, manteniendo solo un número específico de los últimos. Por ejemplo, si tienes una lista larga de mensajes y solo quieres mantener los últimos dos, esta función hará eso por ti.\n",
    "* La función lambda funciona en conjunto con la función `limited_memory_of_messages`. Aquí hay un desglose simple:\n",
    "\n",
    "    1. **Función Lambda**: La palabra clave `lambda` se usa para crear una pequeña función anónima en Python. La función `lambda` definida aquí toma un argumento, `x`.\n",
    "\n",
    "    2. **Argumento de la función**: Se espera que el argumento `x` sea un diccionario que contenga una clave llamada `\"messages\"`. El valor asociado con esta clave es una lista de mensajes.\n",
    "\n",
    "    3. **Cuerpo de la función**: El cuerpo de la función `lambda` llama a la función `limited_memory_of_messages`. Pasa la lista de mensajes encontrada en `x[\"messages\"]` a esta función.\n",
    "\n",
    "    4. **Comportamiento predeterminado de limited_memory_of_messages**: Dado que la función `lambda` no especifica el parámetro `number_of_messages_to_keep` cuando llama a `limited_memory_of_messages`, esta última tomará por defecto los últimos 2 mensajes de la lista (como se define en la función anterior).\n",
    "\n",
    "En esencia, la función `lambda` es una forma abreviada de aplicar la función `limited_memory_of_messages` a la lista de mensajes contenida dentro de un diccionario. Recorta automáticamente la lista a los últimos dos mensajes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98d2fd-4e32-4c71-a0c0-99701534f551",
   "metadata": {},
   "source": [
    "**Creemos ahora nuestro nuevo chatbot con historial de mensajes limitado**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d4cd1-2165-451d-939f-66f9cc898c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un chatbot con historial de mensajes limitado\n",
    "chatbot_with_limited_message_history = RunnableWithMessageHistory(\n",
    "    limitedMemoryChain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39981-02c7-4d10-a4a8-2efbe9bb3c89",
   "metadata": {},
   "source": [
    "## Agreguemos 2 mensajes más a la conversación de la sesión1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76687e6a-2bbf-450f-8310-7011646fea3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a fun choice! Vespa scooters are known for their classic and stylish design. They are also great for getting around town and exploring new places. What is it about Vespa scooters that you like the most?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Mis vehículos favoritos son los scooters Vespa.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a9b0c-7ae5-4f3b-b93b-06462c6d3199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'San Francisco is a beautiful city with its iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and cable cars. The diverse culture, amazing food scene, and stunning views of the bay make it a favorite for many people. What do you love most about San Francisco?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Mi ciudad favorita es San Francisco.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c688e6-3e9f-4c11-a4f7-38eb8dd35666",
   "metadata": {},
   "source": [
    "## La memoria del chatbot ahora tiene 4 mensajes. Comprobemos el Chatbot con memoria limitada.\n",
    "* Recuerda, este chatbot solo recuerda los últimos 2 mensajes, por lo que si le preguntamos sobre el primer mensaje no debería recordarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16875068-39fd-419e-84b0-f3363f30a3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI assistant, I don't have access to personal information about you, such as your favorite color. If you'd like to share your favorite color with me, I'd be happy to discuss it further.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes limitado y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_limited_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"¿cuál es mi color favorito?\")],\n",
    "    },\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9989ae1-d75b-4b8f-9235-b4eb110e102d",
   "metadata": {},
   "source": [
    "* El chatbot con memoria limitada se ha comportado como esperábamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324091a-dc49-42af-b638-324dc646cdae",
   "metadata": {},
   "source": [
    "## Finalmente, comparemos la respuesta anterior con la proporcionada por el Chatbot con memoria ilimitada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e1915-dabf-4591-82cc-a0fa8b465ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoca al chatbot con historial de mensajes y la configuración de la sesión 1\n",
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"¿cuál es mi color favorito?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "# Imprime el contenido de la respuesta del chatbot\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e34b2-3c42-4ef7-9deb-18c2ec374adc",
   "metadata": {},
   "source": [
    "* Como puedes ver, este chatbot recuerda nuestro primer mensaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483274a-ad1f-4079-b053-ebdcde113ec0",
   "metadata": {},
   "source": [
    "## Cómo ejecutar el código desde Visual Studio Code\n",
    "* En Visual Studio Code, ve al archivo 004-invoke-stream-batch.py\n",
    "* En la terminal, asegúrate de estar en el directorio del archivo y ejecuta:\n",
    "    * python 002-advanced-chatbot.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
